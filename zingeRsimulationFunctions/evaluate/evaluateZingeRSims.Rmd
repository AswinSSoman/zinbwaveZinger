---
title: "evaluate zingeR simulation variants"
author: "Koen Van den Berge"
date: "31 August 2017"
output: html_document
---

```{r preprocess}
setwd("~/Dropbox/phdKoen/singleCell/zinbwaveZingerGithub/zinbwaveZinger/zingeRsimulations/evaluate/")
knitr::opts_chunk$set(fig.align="center", cache=TRUE, error=FALSE, message=FALSE, warning=TRUE)
library(gamlss)
library(gamlss.tr)
library(Biobase)
library(edgeR)
library(scales)
library(DESeq2)
library(iCOBRA) # roc
library(limma)
library(genefilter) #filtered pvalues
library(RColorBrewer)
library(knitr)
library(ggplot2)
library(cowplot)
library(MultiAssayExperiment)
library(SummarizedExperiment)
library(countsimQC)
# use new simulation.
#library(zingeR)
source("../../zingeRsimulations/simulationHelpFunctions_v7_diffInZero.R")
# islam
load("../../datasets/islam.rda")
islam=islam[rowSums(islam>0)>=5,]
cellType = unlist(lapply(strsplit(colnames(islam),split="_"),function(x) x[1]))
dds_origIslam <- DESeqDataSetFromMatrix(countData = islam,
                                  colData = data.frame(group = cellType, sample = colnames(islam),
                                                       row.names = colnames(islam),
                                                       stringsAsFactors = FALSE),
                                  design = ~ group)

#GSE74596. downloaded from conquer.
pathGSE74596 = "/Users/koenvandenberge/PhD_Data/singleCell/conquer/"
mae <- readRDS(paste0(pathGSE74596,"GSE74596.rds"))
mae <- updateObject(mae)
pdata <- colData(mae)
groupid <- "source_name_ch1"
keepgroups <- c("Single_cell_RNA-seq_NKT0", "Single_cell_RNA-seq_NKT17")
if (length(groupid) > 1) {
 pdata[, paste(groupid, collapse = ".")] <- as.character(interaction(as.data.frame(pdata[, groupid])))
 groupid <- paste(groupid, collapse = ".")
}
counts <- assays(experiments(mae)[["gene"]])[["count_lstpm"]]
stopifnot(all(colnames(counts) == rownames(pdata)))
keep <- which(pdata[, groupid] %in% keepgroups)
counts <- round(counts[, keep])
counts <- counts[rowSums(counts > 0) > 1, ]
countsGSENotFiltered=counts
counts <- counts[rowSums(counts > 0) > 5, ]
countsGSE=counts
group <- as.character(pdata[keep, groupid])
nrowEstcounts = nrow(countsGSE)
set.seed(2)
sampleRowsGSE = sample(1:nrow(countsGSENotFiltered),nrowEstcounts, replace=FALSE)
dds_origGSE74596 <- DESeqDataSetFromMatrix(countData = countsGSENotFiltered[sampleRowsGSE,],
                                  colData = data.frame(group = group, sample = colnames(counts), row.names = colnames(counts), stringsAsFactors = FALSE), design = ~ group)

## trapnell
trapnellAssay72 <- readRDS("/Users/koenvandenberge/PhD_Data/singleCell/conquer/GSE52529-GPL11154.rds")
trapnellAssay72 = updateObject(trapnellAssay72)
trapnellAssay <- readRDS("/Users/koenvandenberge/PhD_Data/singleCell/conquer/GSE52529-GPL16791.rds")
trapnellAssay = updateObject(trapnellAssay)
trapnellAssay48 <- trapnellAssay[,colData(trapnellAssay)[,"characteristics_ch1.1"] == "hour post serum-switch: 48"]
countsTrapnell72 <- round(assay(experiments(trapnellAssay72)$gene,"count"))
id48=colData(trapnellAssay)[,"characteristics_ch1.1"] == "hour post serum-switch: 48"
countsTrapnell48 <- round(assay(experiments(trapnellAssay)$gene[,id48],"count"))
#wells containing debris
debris72 = colData(trapnellAssay72)[,"characteristics_ch1.2"]=="debris: TRUE"
debris48 = colData(trapnellAssay48)[,"characteristics_ch1.2"]=="debris: TRUE"
#wells that did not contain one cell
one72 = colData(trapnellAssay72)[,"characteristics_ch1.4"]!="cells in well: 1"
one48 = colData(trapnellAssay48)[,"characteristics_ch1.4"]!="cells in well: 1"
# remove
countsTrapnell72 = countsTrapnell72[,(!debris72 & !one72)]
countsTrapnell48 = countsTrapnell48[,(!debris48 & !one48)]
countsTrapnell <- cbind(countsTrapnell48,countsTrapnell72)
countsTrapnell <- countsTrapnell[rowSums(countsTrapnell>0)>9,] #expression in at least 10 out of 149 samples. Remains 24,576 genes and 149 samples.
rm(trapnellAssay)
timePoint=factor(c(rep(48,85),rep(72,64)))
dds_origTrapnell <- DESeqDataSetFromMatrix(countData = countsTrapnell,
                                  colData = data.frame(group = timePoint, sample = colnames(countsTrapnell), row.names = colnames(countsTrapnell), stringsAsFactors = FALSE), design = ~ group)
```


# Unnormalized model-based lambda

```{r unnormalized model based}
source("./getParamsZTNBModelBasedLambda.R")
source("./NBsimSingleCellUnnormalizedLambda.R")
#paramsIslam = getDatasetZTNB(counts=islam, design=model.matrix(~cellType))
#save(paramsIslam,file="paramsIslamUnnormalizedModelBased.rda")
load("paramsIslamUnnormalizedModelBased.rda")
nSamples=ncol(islam)
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(islam) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(islam),nSamples,replace=TRUE) #library sizes
islamSim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = islam, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsIslam,
                                lib.size = libSizes)
dds_zingerIslam <- DESeqDataSetFromMatrix(countData = islamSim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(islamSim$counts),
                                                         row.names = colnames(islamSim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)

countsimQCReport(ddsList=list(original=dds_origIslam,zingeR=dds_zingerIslam),
                 outputFile="~/islamUnnormalizedModelBased.html",
                 description = "islam dataset, unnormalized model-based lambda")

#paramsGSE = getDatasetZTNB(counts=counts, design=model.matrix(~group))
#save(paramsGSE,file="paramsGSEUnnormalizedModelBased.rda")
load("paramsGSEUnnormalizedModelBased.rda")
nSamples=ncol(counts)-1
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(counts) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(counts),nSamples,replace=TRUE) #library sizes
GSESim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = counts, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsGSE,
                                lib.size = libSizes)
dds_zingerGSE <- DESeqDataSetFromMatrix(countData = GSESim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(GSESim$counts),
                                                         row.names = colnames(GSESim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)
countsimQCReport(ddsList=list(original=dds_origGSE74596,zingeR=dds_zingerGSE), outputFile="~/GSEUnnormalizedModelBased.html",
description="GSE, unnormalized model-based lambda")
```


# Normalized model-based lambda


```{r normalized model-based}
source("./getParamsZTNBModelBasedLambda.R")
source("./NBsimSingleCellNormalizedLambda.R")
nSamples=ncol(islam)
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(islam) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(islam),nSamples,replace=TRUE) #library sizes
islamSim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = islam, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsIslam,
                                lib.size = libSizes)
dds_zingerIslam <- DESeqDataSetFromMatrix(countData = islamSim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(islamSim$counts),
                                                         row.names = colnames(islamSim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)

countsimQCReport(ddsList=list(original=dds_origIslam,zingeR=dds_zingerIslam),
                 outputFile="~/islamNormalizedModelBased.html",
                 description = "islam dataset, normalized model-based lambda",
                 forceOverwrite = TRUE)

nSamples=ncol(counts)-1
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(counts) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(counts),nSamples,replace=TRUE) #library sizes
GSESim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = counts, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsGSE,
                                lib.size = libSizes)
dds_zingerGSE <- DESeqDataSetFromMatrix(countData = GSESim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(GSESim$counts),
                                                         row.names = colnames(GSESim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)
countsimQCReport(ddsList=list(original=dds_origGSE74596,zingeR=dds_zingerGSE), outputFile="~/GSENormalizedModelBased.html",
                description = "GSE dataset, normalized model-based lambda")
```


# Unnormalized empirical lambda

```{r unnormalized empirical}
source("./getParamsZTNBEmpiricalLambda.R")
source("./NBsimSingleCellUnnormalizedLambda.R")
#paramsIslam = getDatasetZTNB(counts=islam, design=model.matrix(~cellType))
#save(paramsIslam,file="paramsIslamUnnormalizedEmpirical.rda")
load("paramsIslamUnnormalizedEmpirical.rda")
nSamples=ncol(islam)
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(islam) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(islam),nSamples,replace=TRUE) #library sizes
islamSim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = islam, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsIslam,
                                lib.size = libSizes)
dds_zingerIslam <- DESeqDataSetFromMatrix(countData = islamSim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(islamSim$counts),
                                                         row.names = colnames(islamSim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)

countsimQCReport(ddsList=list(original=dds_origIslam,zingeR=dds_zingerIslam),
                 outputFile="~/islamUnnormalizedEmpirical.html",
                 description = "islam dataset, unnormalized empirical lambda")

#paramsGSE = getDatasetZTNB(counts=counts, design=model.matrix(~group))
#save(paramsGSE,file="paramsGSEUnnormalizedEmpirical.rda")
load("paramsGSEUnnormalizedEmpirical.rda")
nSamples=ncol(counts)-1
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(counts) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(counts),nSamples,replace=TRUE) #library sizes
GSESim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = counts, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsGSE,
                                lib.size = libSizes)
dds_zingerGSE <- DESeqDataSetFromMatrix(countData = GSESim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(GSESim$counts),
                                                         row.names = colnames(GSESim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)
countsimQCReport(ddsList=list(original=dds_origGSE74596,zingeR=dds_zingerGSE),
                outputFile="~/GSEUnnormalizedEmpirical.html",
                description="GSE dataset, unnormalized empirical")

```


# Normalized empirical lambda

```{r normalized empirical}
source("./getParamsZTNBEmpiricalLambda.R")
source("./NBsimSingleCellNormalizedLambda.R")
nSamples=ncol(islam)
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(islam) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(islam),nSamples,replace=TRUE) #library sizes
islamSim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = islam, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsIslam,
                                lib.size = libSizes)
dds_zingerIslam <- DESeqDataSetFromMatrix(countData = islamSim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(islamSim$counts),
                                                         row.names = colnames(islamSim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)

countsimQCReport(ddsList=list(original=dds_origIslam,zingeR=dds_zingerIslam),
                 outputFile="~/islamNormalizedEmpirical.html",
                 description = "islam dataset, normalized empirical lambda")

nSamples=ncol(counts)-1
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(counts) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(counts),nSamples,replace=TRUE) #library sizes
GSESim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = counts, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsGSE,
                                lib.size = libSizes)
dds_zingerGSE <- DESeqDataSetFromMatrix(countData = GSESim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(GSESim$counts),
                                                         row.names = colnames(GSESim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)
countsimQCReport(ddsList=list(original=dds_origGSE74596,zingeR=dds_zingerGSE),
                outputFile="~/GSENormalizedEmpirical.html",
                description="GSE dataset, normalized empirical")



```

# MoM estimation of dispersion

```{r}
getParamsMoM = function(counts){
    countsModel = counts
    n=length(countsModel)
    p=1
    mu=mean(countsModel)
    phiMoM = 1/(n-p) * sum( ((countsModel - mu)^2 - mu)/(mu^2) )
    return(phiMoM)
}


getExprFraction = function(counts, offset){
  offsetModel=offset[counts>0]
  countsModel = counts[counts>0]
  mean(countsModel/offsetModel)
}


getDatasetMoM = function(counts, design, drop.extreme.dispersion = FALSE, cpm= "AveLogCPM"){

        #### estimate lambda and overdispersion based on ZTNB.
	d <- DGEList(counts)
	cp <- cpm(d,normalized.lib.sizes=TRUE)
	dFiltered=d
	dFiltered <- edgeR::calcNormFactors(dFiltered)
  dFiltered$AveLogCPM <- aveLogCPM(dFiltered)
	dispMoM=apply(dFiltered$counts,1,function(x) getParamsMoM(counts=x))
  lambdaMoM=apply(dFiltered$counts,1,function(x) getExprFraction(counts=x, offset=colSums(dFiltered$counts)))
  params=cbind(dispMoM,lambdaMoM)
	rmRows = which(params[,2]>1) #impossibly high lambda
	rmRows2 = which(params[,2]==0) #zero lambda
	naRows = which(apply(params,1, function(row) any(is.na(row)))) #not fitted
	nonZeroDispRows = which(params[,1]<0 | params[,1]==0) #negative dispersion
	throwRows = c(rmRows,rmRows2,naRows,nonZeroDispRows)
	params = params[-throwRows,]

	### estimate logistic GAM P(zero) ~ s(aveLogCPM) + logLibSize
	### use unfiltered data for this model.
  require(mgcv)
	propZero = colMeans(counts==0)
	propZeroGene = rowMeans(counts==0)
	d <- DGEList(counts)
	d <- edgeR::calcNormFactors(d)
	if(cpm=="AveLogCPM"){ avCpm <- aveLogCPM(d)} else if(cpm=="aCpm"){ avCpm <- aCPM(d$counts)} else {stop("cpm must be either AveLogCPM or aCPM")}
	cpmHist = hist(avCpm, breaks=150, plot=FALSE)
    	breaks = cpmHist$breaks
    	mids = cpmHist$mids
    	midsHlp=rep(mids,ncol(d$counts))
	logLibSize = log(colSums(counts))
    	logLibHlp=rep(logLibSize,each=length(mids))
	binHlp=sapply(breaks[-length(breaks)],function(x) avCpm>x)
  	binId=apply(binHlp,1,function(x) max(which(x)))
	nonNullCounts = t(sapply(1:length(mids), function(bin){
			    binRows <- binId==bin
			    if(sum(binRows)==0) rep(0,ncol(counts)) else
			    if(sum(binRows)==1) (counts[which(binRows),]!=0)*1 else
				colSums(counts[which(binRows),]!=0)
	    }))
	nullCounts = t(sapply(1:length(mids), function(bin){
		    	binRows <- binId==bin
		    	if(sum(binRows)==0) rep(0,ncol(counts)) else
		    	if(sum(binRows)==1) (counts[which(binRows),]==0)*1 else
			    colSums(counts[which(binRows),]==0)
	    }))
	expectCounts=cbind(c(nullCounts),c(nonNullCounts))
	#zeroFit=mgcv::gam(expectCounts~s(midsHlp)+logLibHlp,family=binomial)
	zeroFit=gam(expectCounts~s(midsHlp,by=logLibHlp),family=binomial)

	### drop extreme dispersions
        dFiltered$AveLogCPM <- aveLogCPM(dFiltered)
	dFiltered$AveLogCPM <- dFiltered$AveLogCPM[-throwRows]
	propZeroGene = propZeroGene[-throwRows]
	params=data.frame(dispersion=params[,1], lambda=params[,2], aveLogCpm=dFiltered$AveLogCPM, propZeroGene=propZeroGene)
	dispersion <- params$dispersion
	AveLogCPM <- params$aveLogCpm
	lambda <- params$lambda
	propZeroGene <- params$propZeroGene

	if(is.numeric(drop.extreme.dispersion))
	{
		bad <- quantile(dispersion, 1-drop.extreme.dispersion, names = FALSE, na.rm=TRUE)
		ids <- dispersion <= bad
		AveLogCPM <- AveLogCPM[ids]
		dispersion <- dispersion[ids]
		lambda <- lambda[ids]
		propZeroGene <- propZeroGene[ids]
		params <- params[ids,]
		dFiltered <- dFiltered[ids,]
	}
	#lambda=lambda/sum(lambda) #make sure they sum to 1
	dataset.AveLogCPM <- AveLogCPM
	dataset.dispersion <- dispersion
	dataset.lambda <- lambda
	dataset.propZeroGene <- propZeroGene
	dataset.lib.size <- d$samples$lib.size
	dataset.nTags <- nrow(d)
	list(dataset.AveLogCPM = dataset.AveLogCPM, dataset.dispersion = dataset.dispersion, dataset.lib.size = dataset.lib.size, dataset.nTags = dataset.nTags, dataset.propZeroFit=zeroFit, dataset.lambda=lambda, dataset.propZeroGene=propZeroGene, dataset.breaks = breaks, dataset.cpm=cpm)
}

#### islam
paramsIslam = getDatasetMoM(counts=islam, design=model.matrix(~cellType))
source("./NBsimSingleCellUnnormalizedLambda.R")
nSamples=ncol(islam)
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(islam) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(islam),nSamples,replace=TRUE) #library sizes
islamSim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = islam, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsIslam,
                                lib.size = libSizes)
dds_zingerIslam <- DESeqDataSetFromMatrix(countData = islamSim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(islamSim$counts),
                                                         row.names = colnames(islamSim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)

countsimQCReport(ddsList=list(original=dds_origIslam,zingeR=dds_zingerIslam),
                 outputFile="~/islamMoMUnnormalized.html",
                 description = "islam dataset, unnormalized MoM ")







### GSE
countsGSE=counts
paramsGSE = getDatasetMoM(counts=countsGSE, design=model.matrix(~group))

source("./NBsimSingleCellNormalizedLambda.R")
nSamples=ncol(counts)-1
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(counts) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(counts),nSamples,replace=TRUE) #library sizes
GSESim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = counts, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsGSE,
                                lib.size = libSizes)
dds_zingerGSE <- DESeqDataSetFromMatrix(countData = GSESim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(GSESim$counts),
                                                         row.names = colnames(GSESim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)

countsimQCReport(ddsList=list(original=dds_origGSE74596,zingeR=dds_zingerGSE),
                outputFile="~/GSEMoMNormalized.html",
                description="GSE dataset, normalized Method of Moments")

hist(paramsGSE$dispersion)


source("./NBsimSingleCellUnnormalizedLambda.R")
nSamples=ncol(counts)-1
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(counts) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(counts),nSamples,replace=TRUE) #library sizes
GSESim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = counts, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsGSE,
                                lib.size = libSizes)

plot(x=aveLogCPM(GSESim),y=rowMeans(GSESim$counts==0))
plot(x=log(colSums(GSESim$counts)),y=colMeans(GSESim$counts==0))


dds_zingerGSE <- DESeqDataSetFromMatrix(countData = GSESim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(GSESim$counts),
                                                         row.names = colnames(GSESim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)

countsimQCReport(ddsList=list(original=dds_origGSE74596,zingeR=dds_zingerGSE),
                outputFile="~/GSEMoMUnnormalized.html",
                description="GSE dataset, unnormalized Method of Moments")
```

# MoM estimation of dispersion on positive counts only

```{r}
####### on positive counts
getParamsMoMPositive = function(counts){
    countsModel = counts[counts>0]
    n=length(countsModel)
    p=1
    mu=mean(countsModel)
    phiMoM = 1/(n-p) * sum( ((countsModel - mu)^2 - mu)/(mu^2) )
    return(phiMoM)
}


getDatasetMoMPositive = function(counts, design, drop.extreme.dispersion = FALSE, cpm= "AveLogCPM"){

        #### estimate lambda and overdispersion based on ZTNB.
	d <- DGEList(counts)
	cp <- cpm(d,normalized.lib.sizes=TRUE)
	dFiltered=d
	dFiltered <- edgeR::calcNormFactors(dFiltered)
  dFiltered$AveLogCPM <- aveLogCPM(dFiltered)
	dispMoM=apply(dFiltered$counts,1,function(x) getParamsMoMPositive(counts=x))
  lambdaMoM=apply(dFiltered$counts,1,function(x) getExprFraction(counts=x, offset=colSums(dFiltered$counts)))
  params=cbind(dispMoM,lambdaMoM)
	rmRows = which(params[,2]>1) #impossibly high lambda
	rmRows2 = which(params[,2]==0) #zero lambda
	naRows = which(apply(params,1, function(row) any(is.na(row)))) #not fitted
	nonZeroDispRows = which(params[,1]<0 | params[,1]==0) #negative dispersion
	throwRows = c(rmRows,rmRows2,naRows,nonZeroDispRows)
	params = params[-throwRows,]

	### estimate logistic GAM P(zero) ~ s(aveLogCPM) + logLibSize
	### use unfiltered data for this model.
  require(mgcv)
	propZero = colMeans(counts==0)
	propZeroGene = rowMeans(counts==0)
	d <- DGEList(counts)
	d <- edgeR::calcNormFactors(d)
	if(cpm=="AveLogCPM"){ avCpm <- aveLogCPM(d)} else if(cpm=="aCpm"){ avCpm <- aCPM(d$counts)} else {stop("cpm must be either AveLogCPM or aCPM")}
	cpmHist = hist(avCpm, breaks=150, plot=FALSE)
    	breaks = cpmHist$breaks
    	mids = cpmHist$mids
    	midsHlp=rep(mids,ncol(d$counts))
	logLibSize = log(colSums(counts))
    	logLibHlp=rep(logLibSize,each=length(mids))
	binHlp=sapply(breaks[-length(breaks)],function(x) avCpm>x)
  	binId=apply(binHlp,1,function(x) max(which(x)))
	nonNullCounts = t(sapply(1:length(mids), function(bin){
			    binRows <- binId==bin
			    if(sum(binRows)==0) rep(0,ncol(counts)) else
			    if(sum(binRows)==1) (counts[which(binRows),]!=0)*1 else
				colSums(counts[which(binRows),]!=0)
	    }))
	nullCounts = t(sapply(1:length(mids), function(bin){
		    	binRows <- binId==bin
		    	if(sum(binRows)==0) rep(0,ncol(counts)) else
		    	if(sum(binRows)==1) (counts[which(binRows),]==0)*1 else
			    colSums(counts[which(binRows),]==0)
	    }))
	expectCounts=cbind(c(nullCounts),c(nonNullCounts))
	#zeroFit=mgcv::gam(expectCounts~s(midsHlp)+logLibHlp,family=binomial)
	zeroFit=gam(expectCounts~s(midsHlp,by=logLibHlp),family=binomial)

	### drop extreme dispersions
        dFiltered$AveLogCPM <- aveLogCPM(dFiltered)
	dFiltered$AveLogCPM <- dFiltered$AveLogCPM[-throwRows]
	propZeroGene = propZeroGene[-throwRows]
	params=data.frame(dispersion=params[,1], lambda=params[,2], aveLogCpm=dFiltered$AveLogCPM, propZeroGene=propZeroGene)
	dispersion <- params$dispersion
	AveLogCPM <- params$aveLogCpm
	lambda <- params$lambda
	propZeroGene <- params$propZeroGene

	if(is.numeric(drop.extreme.dispersion))
	{
		bad <- quantile(dispersion, 1-drop.extreme.dispersion, names = FALSE, na.rm=TRUE)
		ids <- dispersion <= bad
		AveLogCPM <- AveLogCPM[ids]
		dispersion <- dispersion[ids]
		lambda <- lambda[ids]
		propZeroGene <- propZeroGene[ids]
		params <- params[ids,]
		dFiltered <- dFiltered[ids,]
	}
	#lambda=lambda/sum(lambda) #make sure they sum to 1
	dataset.AveLogCPM <- AveLogCPM
	dataset.dispersion <- dispersion
	dataset.lambda <- lambda
	dataset.propZeroGene <- propZeroGene
	dataset.lib.size <- d$samples$lib.size
	dataset.nTags <- nrow(d)
	list(dataset.AveLogCPM = dataset.AveLogCPM, dataset.dispersion = dataset.dispersion, dataset.lib.size = dataset.lib.size, dataset.nTags = dataset.nTags, dataset.propZeroFit=zeroFit, dataset.lambda=lambda, dataset.propZeroGene=propZeroGene, dataset.breaks = breaks, dataset.cpm=cpm)
}


#### islam
paramsIslam = getDatasetMoMPositive(counts=islam, design=model.matrix(~cellType))
source("./NBsimSingleCellUnnormalizedLambda.R")
nSamples=ncol(islam)
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(islam) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(islam),nSamples,replace=TRUE) #library sizes
islamSim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = islam, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsIslam,
                                lib.size = libSizes)
dds_zingerIslam <- DESeqDataSetFromMatrix(countData = islamSim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(islamSim$counts),
                                                         row.names = colnames(islamSim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)

countsimQCReport(ddsList=list(original=dds_origIslam,zingeR=dds_zingerIslam),
                 outputFile="~/islamMoMPositiveUnnormalized.html",
                 description = "islam dataset, unnormalized MoM positive")

### GSE74596
paramsGSE = getDatasetMoMPositive(counts=countsGSE, design=model.matrix(~group))

source("./NBsimSingleCellUnnormalizedLambda.R")
nSamples=ncol(counts)-1
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(counts) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(counts),nSamples,replace=TRUE) #library sizes
GSESim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = counts, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsGSE,
                                lib.size = libSizes)

plot(x=aveLogCPM(GSESim),y=rowMeans(GSESim$counts==0))
plot(x=log(colSums(GSESim$counts)),y=colMeans(GSESim$counts==0))


dds_zingerGSE <- DESeqDataSetFromMatrix(countData = GSESim$counts,
                      colData = data.frame(group = grp, sample = colnames(GSESim$counts), row.names = colnames(GSESim$counts), stringsAsFactors = FALSE), design = ~ group)

countsimQCReport(ddsList=list(original=dds_origGSE74596,zingeR=dds_zingerGSE),
                outputFile="~/GSEMoMPositiveUnnormalized.html",
                description="GSE dataset, unnormalized Method of Moments on positive counts")

### trapnell

### Trapnell params
paramsTrapnell = getDatasetMoMPositive(counts=countsTrapnell, design=model.matrix(~timePoint))
source("./NBsimSingleCellUnnormalizedLambda.R")
nSamples=ncol(countsTrapnell)-1
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(countsTrapnell) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(countsTrapnell),nSamples,replace=TRUE) #library sizes
trapnellSim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = countsTrapnell, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsTrapnell,
                                lib.size = libSizes)

dds_zingerTrapnell <- DESeqDataSetFromMatrix(countData = trapnellSim$counts, colData = data.frame(group = grp, sample = colnames(trapnellSim$counts), row.names = colnames(trapnellSim$counts), stringsAsFactors = FALSE), design = ~ group)

countsimQCReport(ddsList=list(original=dds_origTrapnell,zingeR=dds_zingerTrapnell), outputFile="~/trapnellMoMPositiveUnnormalized.html", description="trapnell dataset, unnormalized Method of Moments on positive counts")

```

# MoM estimation on positive counts only, including a bias correction for the mean.

```{r}
####### on positive counts

getExprFraction = function(counts, offset){
  offsetModel=offset[counts>0]
  countsModel = counts[counts>0]
  mean(countsModel/offsetModel)
}

getParamsMoMPositive = function(counts){
    countsModel = counts[counts>0]
    n=length(countsModel)
    p=1
    mu=mean(countsModel)
    phiMoM = 1/(n-p) * sum( ((countsModel - mu)^2 - mu)/(mu^2) )
    return(phiMoM)
}

reEstimateExprFraction = function(counts, offset, phi, lambda){
  offsetModel=offset[counts>0]
  countsModel = counts[counts>0]
  #lambda=countsModel/offsetModel
  mean(lambda*(1-dnbinom(x=0,mu=lambda*offsetModel,size=1/phi)))
}

reEstimatePhiMoM = function(counts, offset, lambda){
  countsModel = counts[counts>0]
  offsetModel=offset[counts>0]
  n=length(countsModel)
  p=1
  mu=lambda*offsetModel
  phiMoM = 1/(n-p) * sum( ((countsModel - mu)^2 - mu)/(mu^2) )
  return(phiMoM)}

getDatasetMoMPositive = function(counts, design, drop.extreme.dispersion = FALSE, cpm= "AveLogCPM"){

        #### estimate lambda and overdispersion based on ZTNB.
	d <- DGEList(counts)
	cp <- cpm(d,normalized.lib.sizes=TRUE)
	dFiltered=d
	dFiltered <- edgeR::calcNormFactors(dFiltered)
  dFiltered$AveLogCPM <- aveLogCPM(dFiltered)
  ## estimate
  lambdaMoM=apply(dFiltered$counts,1,function(x) getExprFraction(counts=x, offset=colSums(dFiltered$counts)))
	dispMoM=apply(dFiltered$counts,1,function(x) getParamsMoMPositive(counts=x))
  dispMoM[dispMoM<0] = 1e-5
  for(j in 1:1){
  for(i in 1:nrow(dFiltered$counts)) lambdaMoM[i] = reEstimateExprFraction(counts=dFiltered$counts[i,], offset=colSums(dFiltered$counts), phi=dispMoM[i], lambda=lambdaMoM[i])
  for(i in 1:nrow(dFiltered$counts)) dispMoM[i] = reEstimateDispersion(counts=dFiltered$counts[i,], offset=colSums(dFiltered$counts), lambda=lambdaMoM[i], phi=dispMoM[i])
  dispMoM[dispMoM<0] = 1e-5
  }


  # ## iteration 1
  # lambdaMoM2 = vector(length=nrow(dFiltered$counts))
  # for(i in 1:nrow(dFiltered$counts)) lambdaMoM2[i] = reEstimateExprFraction(counts=dFiltered$counts[i,], offset=colSums(dFiltered$counts), phi=dispMoM[i], lambda=lambdaMoM[i])
  #
  # dispMoM2 = vector(length=nrow(dFiltered$counts))
  # for(i in 1:nrow(dFiltered$counts)) dispMoM2[i] = reEstimateDispersion(counts=dFiltered$counts[i,], offset=colSums(dFiltered$counts), lambda=lambdaMoM[i], phi=dispMoM[i])
  # dispMoM2[dispMoM2<0] = 1e-5
  # ## iteration 2
  # lambdaMoM3 = vector(length=nrow(dFiltered$counts))
  # for(i in 1:nrow(dFiltered$counts)) lambdaMoM3[i] = reEstimateExprFraction(counts=dFiltered$counts[i,], offset=colSums(dFiltered$counts), phi=dispMoM2[i], lambda=lambdaMoM2[i])
  #
  # dispMoM3 = vector(length=nrow(dFiltered$counts))
  # for(i in 1:nrow(dFiltered$counts)) dispMoM3[i] = reEstimateDispersion(counts=dFiltered$counts[i,], offset=colSums(dFiltered$counts), lambda=lambdaMoM3[i], phi=dispMoM2[i])
  # dispMoM3[dispMoM3<0] = 1e-5
  ## assume convergence
  params=cbind(dispMoM,lambdaMoM)
	rmRows = which(params[,2]>1) #impossibly high lambda
	rmRows2 = which(params[,2]==0) #zero lambda
	naRows = which(apply(params,1, function(row) any(is.na(row)))) #not fitted
	nonZeroDispRows = which(params[,1]<0 | params[,1]==0) #negative dispersion
	throwRows = c(rmRows,rmRows2,naRows,nonZeroDispRows)
  if(length(throwRows)>0) params = params[-throwRows,]

	### estimate logistic GAM P(zero) ~ s(aveLogCPM) + logLibSize
	### use unfiltered data for this model.
  require(mgcv)
	propZero = colMeans(counts==0)
	propZeroGene = rowMeans(counts==0)
	d <- DGEList(counts)
	d <- edgeR::calcNormFactors(d)
	if(cpm=="AveLogCPM"){ avCpm <- aveLogCPM(d)} else if(cpm=="aCpm"){ avCpm <- aCPM(d$counts)} else {stop("cpm must be either AveLogCPM or aCPM")}
	cpmHist = hist(avCpm, breaks=150, plot=FALSE)
    	breaks = cpmHist$breaks
    	mids = cpmHist$mids
    	midsHlp=rep(mids,ncol(d$counts))
	logLibSize = log(colSums(counts))
    	logLibHlp=rep(logLibSize,each=length(mids))
	binHlp=sapply(breaks[-length(breaks)],function(x) avCpm>x)
  	binId=apply(binHlp,1,function(x) max(which(x)))
	nonNullCounts = t(sapply(1:length(mids), function(bin){
			    binRows <- binId==bin
			    if(sum(binRows)==0) rep(0,ncol(counts)) else
			    if(sum(binRows)==1) (counts[which(binRows),]!=0)*1 else
				colSums(counts[which(binRows),]!=0)
	    }))
	nullCounts = t(sapply(1:length(mids), function(bin){
		    	binRows <- binId==bin
		    	if(sum(binRows)==0) rep(0,ncol(counts)) else
		    	if(sum(binRows)==1) (counts[which(binRows),]==0)*1 else
			    colSums(counts[which(binRows),]==0)
	    }))
	expectCounts=cbind(c(nullCounts),c(nonNullCounts))
	#zeroFit=mgcv::gam(expectCounts~s(midsHlp)+logLibHlp,family=binomial)
	zeroFit=gam(expectCounts~s(midsHlp,by=logLibHlp),family=binomial)

	### drop extreme dispersions
  dFiltered$AveLogCPM <- aveLogCPM(dFiltered)
	if(length(throwRows)>0) dFiltered$AveLogCPM <- dFiltered$AveLogCPM[-throwRows]
	if(length(throwRows)>0) propZeroGene = propZeroGene[-throwRows]
	params=data.frame(dispersion=params[,1], lambda=params[,2], aveLogCpm=dFiltered$AveLogCPM, propZeroGene=propZeroGene)
	dispersion <- params$dispersion
	AveLogCPM <- params$aveLogCpm
	lambda <- params$lambda
	propZeroGene <- params$propZeroGene

	if(is.numeric(drop.extreme.dispersion))
	{
		bad <- quantile(dispersion, 1-drop.extreme.dispersion, names = FALSE, na.rm=TRUE)
		ids <- dispersion <= bad
		AveLogCPM <- AveLogCPM[ids]
		dispersion <- dispersion[ids]
		lambda <- lambda[ids]
		propZeroGene <- propZeroGene[ids]
		params <- params[ids,]
		dFiltered <- dFiltered[ids,]
	}
	#lambda=lambda/sum(lambda) #make sure they sum to 1
	dataset.AveLogCPM <- AveLogCPM
	dataset.dispersion <- dispersion
	dataset.lambda <- lambda
	dataset.propZeroGene <- propZeroGene
	dataset.lib.size <- d$samples$lib.size
	dataset.nTags <- nrow(d)
	list(dataset.AveLogCPM = dataset.AveLogCPM, dataset.dispersion = dataset.dispersion, dataset.lib.size = dataset.lib.size, dataset.nTags = dataset.nTags, dataset.propZeroFit=zeroFit, dataset.lambda=lambda, dataset.propZeroGene=propZeroGene, dataset.breaks = breaks, dataset.cpm=cpm)
}


#### islam
paramsIslam = getDatasetMoMPositive(counts=islam, design=model.matrix(~cellType))

source("./NBsimSingleCellUnnormalizedLambda.R")
nSamples=ncol(islam)
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(islam) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(islam),nSamples,replace=TRUE) #library sizes
islamSim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = islam, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsIslam,
                                lib.size = libSizes)

hist(aveLogCPM(islam), breaks=seq(0,20,0.5), freq=FALSE)
hist(aveLogCPM(islamSim$counts), breaks=seq(0,20,0.5), add=TRUE, col=scales::alpha("steelblue",.3), freq=FALSE)

hist(rowMeans(islam==0), breaks=50, freq=FALSE)
hist(rowMeans(islamSim$counts==0), breaks=50, add=TRUE, col=scales::alpha("steelblue",.3), freq=FALSE)

plot(x=log(colSums(islam)),y=colMeans(islam==0))
points(x=log(colSums(islamSim$counts)),y=colMeans(islamSim$counts==0), col="red")


dds_zingerIslam <- DESeqDataSetFromMatrix(countData = islamSim$counts,
                                    colData = data.frame(group = grp,
                                                         sample = colnames(islamSim$counts),
                                                         row.names = colnames(islamSim$counts),
                                                         stringsAsFactors = FALSE),
                                    design = ~ group)

countsimQCReport(ddsList=list(original=dds_origIslam,zingeR=dds_zingerIslam),
                 outputFile="~/islamMoMPositiveAdjustedUnnormalized.html",
                 description = "islam dataset, unnormalized adjusted MoM positive")

### GSE74596
paramsGSE = getDatasetMoMPositive(counts=countsGSE, design=model.matrix(~group))

source("./NBsimSingleCellUnnormalizedLambda.R")
nSamples=ncol(countsGSE)-1
grp=as.factor(rep(0:1, each = nSamples/2)) #two-group comparison
nTags=nrow(countsGSE) #nr of features
set.seed(11)
DEind = sample(1:nTags,floor(nTags*.1),replace=FALSE) #10% DE
fcSim=(2 + rexp(length(DEind), rate = 1/2)) #fold changes
libSizes=sample(colSums(countsGSE),nSamples,replace=TRUE) #library sizes
GSESim <- NBsimSingleCell(foldDiff = fcSim, ind = DEind,
                                dataset = countsGSE, nTags = nTags,
                                group = grp,
                                verbose = TRUE, params = paramsGSE,
                                lib.size = libSizes)


hist(aveLogCPM(countsGSE), breaks=seq(-1,20,0.5), freq=FALSE)
hist(aveLogCPM(GSESim$counts), breaks=seq(-1,20,0.5), add=TRUE, col=scales::alpha("steelblue",.3), freq=FALSE)

hist(rowMeans(countsGSE==0), breaks=seq(0,1,0.05), freq=FALSE, ylim=c(0,5))
hist(rowMeans(GSESim$counts==0), breaks=seq(0,1,0.05), add=TRUE, col=scales::alpha("steelblue",.3), freq=FALSE)

plot(x=colSums(countsGSE), y=colMeans(countsGSE==0), ylim=c(0.35,0.8))
points(x=colSums(GSESim$counts), y=colMeans(GSESim$counts==0), col=2)

dds_zingerGSE <- DESeqDataSetFromMatrix(countData = GSESim$counts,
                      colData = data.frame(group = grp, sample = colnames(GSESim$counts), row.names = colnames(GSESim$counts), stringsAsFactors = FALSE), design = ~ group)

countsimQCReport(ddsList=list(original=dds_origGSE74596,zingeR=dds_zingerGSE),
                outputFile="~/GSEMoMPositiveAdjustedUnnormalized.html",
                description="GSE dataset, unnormalized adjusted Method of Moments on positive counts")


getExprFraction = function(counts, offset){
  offsetModel=offset[counts>0]
  countsModel = counts[counts>0]
  mean(countsModel/offsetModel)
}

getParamsMoMPositive = function(counts){
    countsModel = counts[counts>0]
    n=length(countsModel)
    p=1
    mu=mean(countsModel)
    phiMoM = 1/(n-p) * sum( ((countsModel - mu)^2 - mu)/(mu^2) )
    return(phiMoM)
}

reEstimateExprFraction = function(counts, offset, phi, lambda){
  offsetModel=offset[counts>0]
  countsModel = counts[counts>0]
  lambda=countsModel/offsetModel
  mean(lambda*(1-dnbinom(x=0,mu=lambda*offsetModel,size=1/phi)))
}

reEstimateDispersion = function(counts, offset, phi, lambda){
    offsetModel=offset[counts>0]
    countsModel = counts[counts>0]
    eYt = mean(countsModel)
    eY = eYt*(1-dnbinom(x=0,mu=lambda*offsetModel,size=1/phi))
    phiMoM = 1/(n-1) * sum( ((countsModel - eY)^2 - eY)/(eY^2) )
    return(phiMoM)
}

```





```{r junk}
 dataset=counts
 group=grp
 nlibs=length(group)
 lib.size=libSizes
 drop.low.lambda=TRUE
 drop.extreme.dispersion=.1
 pUp=.5
 foldDiff=fcSim
 verbose=TRUE
 ind=DEind
 params=paramsGSE
 cpm="AveLogCPM"
 max.dispersion=400
 min.dispersion=0.1

```
